# Прогнозирование оттока клиентов.

Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

## Данные
Признаки:

- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата

Целевой признак
- Exited — факт ухода клиента


## Задача

Изучение моделей оттока клиентов. Построение модели с предельно большим значением F1-меры.

## Ход проекта

В ходе проекта использованны следующие модели:
1. RandomForestClassifier
2. DecisionTreeClassifier
3. LogisticRegression

Для улучшения качества модели использованы методы:
1. upsampling
2. downsampling
3. балансировка классов

Вывод.
Изначальная таблица содержала 10000 строк, 900 из которых были удалены, поскольку в них были пропуски в местах с важной для прогнозирования информацией. Так же были удалены три столбца, которые не были необходимы для обучения модели. Затем Таблица была разбита на признаки и целевой столбец. И Все признаки прошли маштабирование.

Модель RandomForestClassifier сразу смогла получить удовлетворяющий условиям исследавания результат в метрике f1_score и получить accu_score лучше чем у константной модели. DecisionTreeClassifier и LogisticRegression показали себя хуже в разрезе f1_score, но тем не менее качество предсказание моделей было выше чем у константной.

Модель RandomForestClassifier очень хорошо отреагировала на взвешивание классов и на upsamling. А на downsampling модель отрегаировала снижением метрик. Из чего можно сделать вывод, что модель чуствительна к размеру выборки.
Модель DecisionTreeClassifier отреагировала на взвешивание, upsampling и downsamplin небольшим падением качества предсказаний. Модель стала предсказывать хуже чем константная.
Модель LogisticRegression при применении методов балансировки показала улучшение f1_score, но вмести с ним и резкое падение качества предсказний. Начав предсказывать на порядок хуже константной модели.
Я думаю что DecisionTreeClassifier и LogisticRegression лучше отреагировали бы на увеличение обучающей выборки, чем на балансироку классов.

Финально было проведено тестирование. В тестировании была использована модель RandomForesClassifier. Обучающая выборка была увеличена за счет валидационной и было произведено взвешивание классов. В тесте модель показала сравнимые результаты, которые были не многим ниже, чем изначалные, но совсем не значительно. В ходе исследования был сделан вывод, что увеличение обучающей выборки приводит к улучшению качества обучения при применении модели RandomForestClassifier. И хотя она объективно самая медленная из участвовавших в исследовании, но ее результаты самые высокие.

## Используемые библиотеки

*pandas*

*DecisionTreeClassifier*

*RandomForestClassifier *

*LogisticRegression*

*GradientBoostingClassifier*

*sklearn*

*mathplotlib*